
Step-by-Step Implementation Plan
✅ Step 0: Setup
Choose a suitable LLM (e.g., Mistral-7B, LLaMA-2-7B, Zephyr) using HuggingFace Transformers.

Use Python with frameworks like LangChain, Transformers, and Gradio or Streamlit for the GUI.

Create a GitHub repository for version control and submission.

✅ Step 1: Chat with Memory
Goal: Enable the agent to remember past interactions within a conversation.

Tasks:

Use a memory mechanism (e.g., LangChain’s ConversationBufferMemory or a custom context manager).

Store past messages and include relevant ones in each new prompt.

Implement context window management (e.g., summarization or smart truncation of old messages).

✅ Step 2: Implement RAG (Retrieval-Augmented Generation)
Goal: Enhance LLM responses by retrieving external document chunks (e.g., from PDFs).

Tasks:

PDF Parsing: Use PyMuPDF or pdfminer.six to extract text.

Chunking: Break text into chunks (e.g., 100 words each).

Embedding: Generate embeddings using sentence-transformers (e.g., all-MiniLM-L6-v2).

Indexing: Store embeddings in FAISS (IndexFlatL2).

Querying: For each user query, compute embedding → retrieve top-k chunks → pass them to the LLM as context.

✅ Step 3: Function Calling
Goal: Detect when the user’s query requires external function execution (e.g., web search or weather).

Tasks:

Create mock functions (e.g., get_weather, search_web) and wrap them.

Design prompt templates to let the LLM "choose" or "trigger" function calls.

Use output from the function to generate the final LLM response.

✅ Step 4: Web Search Trigger
Goal: Automatically detect when the query needs web data and fetch it.

Tasks:

Use a binary classification LLM prompt to determine if the user input needs a search (Yes/No).

If Yes:

Use Exa Search API (or any other search API like SerpAPI or Bing).

Summarize top 3 results and inject them into the next prompt.

✅ Step 5: Implement the “20 Questions” Game
Goal: Make the chatbot capable of playing a game where it guesses a word with Yes/No questions.

Tasks:

Implement interaction loop:

LLM asks yes/no questions based on a guessing strategy.

Use provided test.py and ValidatorModel for validation.

Use evaluate_20Q.py -N 100 to test performance.

Handle loss/win conditions and exit logic.

Train or fine-tune a small classifier/prompt to detect if the user wants to play the game.

✅ Step 6: GUI Design
Goal: Create a user-friendly interface using Gradio or Streamlit.

Tasks:

Design input/output areas.

Add buttons for enabling/disabling features like RAG, game, or function-calling.

Show conversation history and possibly retrieved documents or functions triggered.

✅ Step 7: Testing & Submission
Save conversation logs and validate model outputs.

Ensure reproducibility: code must run without errors.

Submit:

ZIP file with code + results

GitHub repository link
